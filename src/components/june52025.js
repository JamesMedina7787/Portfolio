
      import React, { Component } from 'react';
// import surf from './pictures/surf.jpg'
const blogContent= {
  flex:'3',
  border:"2px dotted black",
  padding: "10px",
  margin: '30px',
    width:'100%',
  fontSize: '1.38em',
  content:    `Social Media, Algorithms, and the Future of Visibility in Entertainment

The entertainment industry has undergone massive transformation with the rise of social media platforms like TikTok, YouTube, and Instagram. These platforms have shifted power away from traditional gatekeepers and opened doors for creators of all backgrounds to share their voices. In theory, we now live in a world where anyone can become famous or successful with nothing more than a phone and an idea. But in reality, things aren’t that simple. Money, algorithms, and corporate interests play a much larger role than people might realize; in determining who gets seen, who gets ignored, and who gets rewarded. While these platforms have created new paths for visibility, the systems behind them have also raised major ethical concerns about fairness, equal opportunity, and the future of creativity. In this paper, I explore whether social media has increased exposure opportunities. I wonder if alone is no longer enough. Because platforms are structured to favor money, engagement, and brand alignment, access and success are increasingly reserved for those who can play the game—and afford to pay the toll.

The Conversation So Far
Scholars, journalists, and creators have all joined an ongoing conversation about the ethics of digital access and visibility. One of the earliest and most foundational voices in that conversation is Lawrence Lessig, author of Code: Version 2.0. Lessig argues that the architecture of cyberspace and specifically the underlying software code that platforms run on; acts as a kind of law. He explains this “code is law” because it governs user behavior, opportunity, and freedom. One of his most relevant ideas for this paper is the “monetization of exposure,” where visibility on digital platforms is increasingly tied to commercial interests. Lessig warns that algorithms do not simply present us with neutral or popular content. Instead, they favor what is profitable, leading to a privatized form of censorship in which companies; not people, decide what gets amplified. This idea sets the stage for how money corrupts. It’s just like the old saying by Lord Acton: “Power tends to corrupt, and absolute power corrupts absolutely”. People put so much importance on money understandably. The lack of money denies us our children, shelter, and respect which are carnal human needs. Is it absolutely necessary that the digital world reflect this on society? Entertainment has always been a mirror for society. In some ways it's inevitable that; left to the natural order of things, social media would wind up this way as well.
Stuart Cunningham and David Craig build on this idea in their book Social Media Entertainment: The New Intersection of Hollywood and Silicon Valley. They argue that social media platforms have given rise to a new kind of entertainment industry, where fame can be built outside of the traditional studio system. They introduce the term “Social Media Entertainment” (SME) to describe this shift. A key part of their argument is that social media allows marginalized creators—such as LGBTQ, disabled, or BIPOC voices—to build communities and gain visibility outside of mainstream media. They refer to these communities as “counterpublics.” However, they also note that these same platforms are controlled by profit-driven algorithms that often end up reinforcing the same hierarchies they promised to disrupt. In other words, social media has opened the door, but it hasn’t necessarily leveled the playing field. The algorithms would inevitably in some ways echo the legacy of industry made celebrity appeal. For instance all voices are able to be heard, but human nature might garner unfair favoritism to attractive and flashy types of characters. The algorithms pick up on this and keep the pendulum swinging to some degree. Don’t get me wrong; this is not necessarily a bad thing. It’s like saying beauty pageants are unfair. I think that is a ridiculous argument to make. The free market should have the freedom to exist on any of these platforms. I think that is a value worth protecting in its own right.
Jean Burgess and Joshua Green’s work YouTube: Online Video and Participatory Culture further explains how YouTube, which started as a space for amateurs and creative hobbyists, has evolved into a platform where visibility is dictated by commercial value. They examine the role of algorithmic recommendation systems, which decide what people see based on engagement data. Their analysis shows that while anyone can technically post a video, the likelihood of that video being seen depends heavily on how well it performs according to the platform’s internal metrics. This means creators must learn to play the algorithm: posting at the right time, using the right hashtags, and tailoring their work to trends. This performance-driven system favors consistency, branding, and optimization over raw creativity or artistic risk. I think this aspect of the subject is fair game in my opinion. It’s like winning a video game. The old argument that if the game was easy noone would want to play it. To some degree we should program the platforms to root out the hacks. I wouldn't blame anyone for gaming the systems though.
Crystal Abidin’s book Internet Celebrity: Understanding Fame Online gives us another angle. Her work focuses on influencers and how they use personal branding to create a sense of intimacy and authenticity. She introduces the idea of “calibrated amateurism,” where influencers deliberately craft their image to appear casual, spontaneous, and relatable; even though much of it is carefully planned and curated. This concept highlights how today’s visibility is tied not just to content but to identity management. The line between real and performed has blurred. Abidin’s analysis is especially relevant to younger generations who now look to influencers, not celebrities, as cultural role models. Yet her work also shows how success depends on careful branding, leaving behind those who don’t or can’t package themselves in the right way. It reminds me of Ms. Rachel; she wears childrens attire and speaks in a way that appeals to that specific audience. It proves that it’s beyond just algorithms and monetization. This subject is of a way broader scope than any argument that could be scientifically measured. 
Safiya Umoja Noble’s Algorithms of Oppression shifts the focus from visibility to bias. Her research uncovers how search engines and algorithms reinforce racial and gender stereotypes. Noble shows that even when users are simply searching for information, what they find is shaped by underlying systems that reflect the values of the companies behind them. This is important because it suggests that bias isn’t just a human problem—it’s embedded in the systems we use. If marginalized groups are already being stereotyped or misrepresented in search results and recommendations, how can they compete for visibility and success in a digital space that’s stacked against them?
Tarleton Gillespie dives into the hidden world of platform control in his book Custodians of the Internet. He reveals how content moderation policies and algorithmic filtering shape what we see, what we don’t, and who gets silenced. Gillespie argues that moderation isn’t just about removing harmful material; it’s about curating a platform’s identity. This means platforms actively promote certain types of voices and bury others, depending on what aligns with their branding or what’s least risky to advertisers. For creators, this often means censoring themselves, avoiding controversial topics, or sticking to algorithm-friendly formats. Gillespie’s work ties in with Lessig’s idea that platforms act like lawmakers. They determine what kinds of voices are rewarded and which ones are quietly removed from view. This is where opponents of censorship would come into the discussion. I’ve personally noticed that the more negative content is becoming increasingly prevalent. I suppose it’s because one person's negative algorithm has a firewall to others. In other words; people don’t mind what others are watching because the algorithm shields them from such content in order to protect the more squeamish. This scares me actually. We could be breeding psychos in the cover of the shadows of the algorithms making them. It’s like rated R movies on steroids. Nowadays, Fans of PG content don’t even realize the explicit content is even out there like in days passed.
In Extremely Online, journalist Taylor Lorenz offers a generational lens. She shows how Gen Z and younger Millennials have grown up with social media and understand its rules better than any other group. These young creators are highly strategic, using platform tools to boost visibility, time their posts, and ride trends. Lorenz emphasizes that this isn’t just entertainment; it’s survival. For many influencers, their income depends on staying relevant in a fast-moving algorithmic world. Lorenz’s work captures how the current system encourages hustle culture, constant production, and the need to stay visible at all times. But not everyone has the time, energy, or resources to play that game indefinitely. I say if the fame is well earned, it is well deserved. I have no problem with those who play the game better and become more successful.
Finally, Siva Vaidhyanathan’s Antisocial Media explores how Facebook’s algorithms prioritizes engagement over truth and fairness. He focuses on how this dynamic fuels polarization and misinformation, but his analysis is relevant to entertainment too. Vaidhyanathan argues that when profit becomes the primary goal, the system naturally favors outrage, drama, and spectacle. For creators in the entertainment world, this means competing not just against each other but against a system that rewards extremes. His critique reinforces the concern that platforms are not neutral; they are machines designed to keep us scrolling and spending, even at the cost of fairness or quality. This concerns me greatly. This is literally like the instigators of the playground manufacturing violence for entertainment. In my childhood I’ve never witnessed more protests, outrage, and partisan outrage than in the days of new. I feel like it’s a direct effect of this concept. It could be the undoing of civilized society. We need to pay attention to how we can come up with a solution to this as members of the computer science community. I feel as if the rush to come up with these entertainment platforms caused this concept to emerge. Profit driven motives encouraged an attitude of can we rather than should we in a race of who would win monopoly over the market. It’s not surprising to me that facebook would be such a source for this complex. It is perhaps the reigning champ of rushed to the top of the monopoly board social media platforms.
What’s Missing from the Conversation
While all these authors provide critical insights into how digital visibility works, one thing that’s often missing is a deeper look at how this affects the perception of talent. The traditional view of fame assumed that talented people would rise to the top. But in today’s world, talent is often less visible than strategy. The best dancer in the world might never go viral if they don’t know how to market themselves. A singer with a voice like Whitney Houston might be buried in the algorithm because they didn’t post a trendy video or pay for promotion.
Also, not enough is said about how access is affected by money. Boosting posts, hiring editors, building sets, buying ad space; all of this takes resources. The idea that “anyone can make it” is mostly a myth. The system rewards those who already have a leg up. And those who challenge the system, whether politically, artistically, or socially; risk being shadowbanned, demonetized, or deplatformed.

A New Way to Frame the Problem
Instead of asking whether social media democratizes access, we should be asking what kind of access it creates and for whom. We need to move beyond the idea that access means freedom. As Lessig, Noble, and Gillespie point out, platforms are not public squares; they are profit machines. What we need is a shift in how we build and govern these spaces.
One solution could be more transparency and regulation around how algorithms work. Platforms should be required to disclose how visibility is determined and allow users more control over their own feeds. We could also imagine public-interest algorithms designed to promote diversity, creativity, and mental wellness over just engagement.
Finally, we need a cultural shift in how we define success. If we can move away from measuring value in likes and followers and instead emphasize connection, creativity, and authenticity, we might be able to reclaim digital space as something more than just a marketplace.

Conclusion
Social media has transformed the entertainment world in ways that are both exciting and troubling. It has made fame feel more accessible, but in reality, it has just created new gatekeepers: algorithms, ad budgets, and engagement metrics. The conversation around these issues has shown that visibility online is not neutral or fair. It is shaped by systems designed for profit. As we think about the future of creativity, we need to ask whether we want our culture to be driven by what makes money; or by what matters. The choice is ours, but only if we recognize the system for what it really is.
Works Cited
Abidin, Crystal. Internet Celebrity: Understanding Fame Online. Emerald Publishing, 2018.

Burgess, Jean, and Joshua Green. YouTube: Online Video and Participatory Culture. Polity Press, 2018.

Cunningham, Stuart, and David Craig. Social Media Entertainment: The New Intersection of Hollywood and Silicon Valley. NYU Press, 2019.

Gillespie, Tarleton. Custodians of the Internet: Platforms, Content Moderation, and the Hidden Decisions that Shape Social Media. Yale University Press, 2018.

Lessig, Lawrence. Code: Version 2.0. Basic Books, 2006.

Lorenz, Taylor. Extremely Online: The Untold Story of Fame, Influence, and Power on the Internet. Simon & Schuster, 2023.

Noble, Safiya Umoja. Algorithms of Oppression: How Search Engines Reinforce Racism. NYU Press, 2018.

Vaidhyanathan, Siva. Antisocial Media: How Facebook Disconnects Us and Undermines Democracy. Oxford University Press, 2018.

`  
};



class june52025 extends Component {
  
    render(){
    return (
      <div style={blogContent} className="February7">
      <p>
{blogContent.content}
      </p>
      </div>
    );
  }
}


export default june52025;